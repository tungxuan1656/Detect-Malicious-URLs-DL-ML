{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import urllib.parse\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import io\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(file):\n",
    "    with open(file, 'r', encoding=\"utf8\") as f:\n",
    "        data = f.readlines()\n",
    "    result = []\n",
    "    for d in data:\n",
    "        d = d.strip()\n",
    "        if (len(d) > 0):\n",
    "            result.append(d)\n",
    "    return result\n",
    "def print_result(X_train, X_test, y_train, y_test, clf, clf_name):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "    TP, FP = matrix[0]\n",
    "    FN, TN = matrix[1]\n",
    "    PPV = (TP * 1.0) / (TP + FP)\n",
    "    TPR = (TP * 1.0) / (TP + FN)\n",
    "    TNR = (FP * 1.0) / (TN + FP)\n",
    "    ACC = (TP + TN) * 1.0 / (TP + TN + FP + FN)\n",
    "    F1 = 2.0 * PPV * TPR / (PPV + TPR)\n",
    "    print(\"%s\\t%.5f\\t%.5f\\t%.5f\\t%.5f\\t%.5f\" %\n",
    "          (clf_name, PPV, TPR, TNR, ACC, F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_requests = loadData('anomalousRequest.txt')\n",
    "good_requests = loadData('normalRequest.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_requests = bad_requests + good_requests\n",
    "yBad = [1] * len(bad_requests)\n",
    "yGood = [0] * len(good_requests)\n",
    "y = yBad + yGood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total requests :  61065\n",
      "Bad requests:  25065\n",
      "Good requests:  36000\n"
     ]
    }
   ],
   "source": [
    "print(\"Total requests : \", len(all_requests))\n",
    "print(\"Bad requests: \", len(bad_requests))\n",
    "print(\"Good requests: \", len(good_requests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=0.0, analyzer=\"char\", sublinear_tf=True, ngram_range=(3, 3))\n",
    "X = vectorizer.fit_transform(all_requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 16824)\t0.023397999047973718\n",
      "  (0, 15969)\t0.023386328381543045\n",
      "  (0, 25962)\t0.01735528642034234\n",
      "  (0, 17512)\t0.01735528642034234\n",
      "  (0, 26170)\t0.01735528642034234\n",
      "  (0, 26099)\t0.01735528642034234\n",
      "  (0, 23045)\t0.01735528642034234\n",
      "  (0, 9621)\t0.01735528642034234\n",
      "  (0, 2264)\t0.01735528642034234\n",
      "  (0, 2442)\t0.01735528642034234\n",
      "  (0, 19972)\t0.01735528642034234\n",
      "  (0, 22239)\t0.01735528642034234\n",
      "  (0, 13711)\t0.01735528642034234\n",
      "  (0, 12379)\t0.01735528642034234\n",
      "  (0, 19818)\t0.01735528642034234\n",
      "  (0, 17462)\t0.01735528642034234\n",
      "  (0, 22689)\t0.01735528642034234\n",
      "  (0, 25345)\t0.01735528642034234\n",
      "  (0, 25750)\t0.01735528642034234\n",
      "  (0, 9625)\t0.01735528642034234\n",
      "  (0, 8300)\t0.01735528642034234\n",
      "  (0, 2925)\t0.01735528642034234\n",
      "  (0, 8291)\t0.017421062352646448\n",
      "  (0, 2645)\t0.017922932745589364\n",
      "  (0, 2521)\t0.017932919878393086\n",
      "  :\t:\n",
      "  (61064, 26121)\t0.10972608485041455\n",
      "  (61064, 15885)\t0.1699500568168579\n",
      "  (61064, 15905)\t0.14219486189792674\n",
      "  (61064, 12672)\t0.23027670513340467\n",
      "  (61064, 25364)\t0.1345185908492071\n",
      "  (61064, 2421)\t0.14415207695511528\n",
      "  (61064, 18344)\t0.14251423454476866\n",
      "  (61064, 20428)\t0.14300717496531035\n",
      "  (61064, 12246)\t0.14271486076128914\n",
      "  (61064, 16820)\t0.14122901773350097\n",
      "  (61064, 15768)\t0.1411460994995851\n",
      "  (61064, 21372)\t0.1407045162829801\n",
      "  (61064, 1999)\t0.18682091914589855\n",
      "  (61064, 18894)\t0.1870118747996238\n",
      "  (61064, 18178)\t0.231546972205117\n",
      "  (61064, 24342)\t0.21074974029354482\n",
      "  (61064, 15937)\t0.19883873654391832\n",
      "  (61064, 23946)\t0.23716053144168628\n",
      "  (61064, 3372)\t0.15696804814961726\n",
      "  (61064, 23911)\t0.24858809022069328\n",
      "  (61064, 26629)\t0.20183341876654576\n",
      "  (61064, 24713)\t0.2257696653229293\n",
      "  (61064, 2467)\t0.2577382511411479\n",
      "  (61064, 21704)\t0.2449692459012852\n",
      "  (61064, 11655)\t0.25693344006133395\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requests for Train:  48852\n",
      "Requests for Test:  12213\n",
      "Use Trigram (n=3). Split Train:Test = 8:2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Requests for Train: \", len(y_train))\n",
    "print(\"Requests for Test: \", len(y_test))\n",
    "print(\"Use Trigram (n=3). Split Train:Test = 8:2.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Activation, Conv1D, GlobalAveragePooling1D, MaxPooling1D, Embedding, Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\tungx\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From c:\\users\\tungx\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Reshape((28847,1), input_shape=(28847,)))\n",
    "model.add(Conv1D(32, 3, activation='relu'))\n",
    "model.add(Conv1D(64, 3, activation='relu'))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\tungx\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 39081 samples, validate on 9771 samples\n",
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=64, epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
