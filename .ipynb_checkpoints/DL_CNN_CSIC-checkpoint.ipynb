{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qRRNvycP1ZE3",
    "outputId": "61ae6be2-d124-4e43-9c87-c2f37c498ac6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from keras.layers import Dense, Activation, Dropout, Conv2D, MaxPooling2D, GlobalMaxPooling2D, Reshape\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kHzwSb3K1ZE9"
   },
   "outputs": [],
   "source": [
    "def loadData(file):\n",
    "    with open(file, 'r', encoding=\"utf8\") as f:\n",
    "        data = f.readlines()\n",
    "    result = []\n",
    "    for d in data:\n",
    "        d = d.strip()\n",
    "        if (len(d) > 0):\n",
    "            result.append(d)\n",
    "    return result\n",
    "def print_result(y_pred, y_test, clf_name):\n",
    "    ACC = accuracy_score(y_pred, y_test)\n",
    "    F1 = f1_score(y_pred, y_test, average='macro')\n",
    "    print(\"%s\\t(accuracy, f1) = (%.5f, %.5f)\"%(clf_name, ACC, F1))\n",
    "def onehot_coding_data(data, char_dict):\n",
    "    # convert\n",
    "    data = [[char_dict[el] for el in line] for line in data]\n",
    "\n",
    "    # set max len element of data\n",
    "    for i in range(len(data)):\n",
    "        if (len(data[i]) < 300):\n",
    "            data[i] = data[i] + [0]*(300 - len(data[i]))\n",
    "        else:\n",
    "            data[i] = data[i][:300]\n",
    "\n",
    "    # one-hot vector\n",
    "    X = np.asarray([to_categorical(i, num_classes=63) for i in data])\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IJCBfNV91ZFA"
   },
   "outputs": [],
   "source": [
    "bad_requests = loadData('normalRequest.txt')\n",
    "good_requests = loadData('anomalousRequest.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6GubTQsn0EDS"
   },
   "outputs": [],
   "source": [
    "all_requests = bad_requests + good_requests\n",
    "y_bad = [1] * len(bad_requests)\n",
    "y_good = [0] * len(good_requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "5P7bA5Nw0GpV",
    "outputId": "fd5ca042-cabc-48dd-ea6b-fbaab930bdde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total requests :  61065\n",
      "Bad requests:  36000\n",
      "Good requests:  25065\n"
     ]
    }
   ],
   "source": [
    "print(\"Total requests : \", len(all_requests))\n",
    "print(\"Bad requests: \", len(bad_requests))\n",
    "print(\"Good requests: \", len(good_requests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dMgj52bj0I3L"
   },
   "outputs": [],
   "source": [
    "normal_train, normal_test, y_normal_train, y_normal_test = train_test_split(good_requests, y_good, test_size = 0.4, random_state = 22)\n",
    "malicious_train, malicious_test, y_malicious_train, y_malicious_test = train_test_split(bad_requests, y_bad, test_size = 0.4, random_state = 22)\n",
    "normal_test, normal_val, y_normal_test, y_normal_val = train_test_split(normal_test, y_normal_test, test_size = 0.5, random_state = 11)\n",
    "malicious_test, malicious_val, y_malicious_test, y_malicious_val = train_test_split(malicious_test, y_malicious_test, test_size = 0.5, random_state = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EevOmjWV0NWy"
   },
   "outputs": [],
   "source": [
    "train = normal_train + malicious_train\n",
    "y_train = y_normal_train + y_malicious_train\n",
    "val = normal_val + malicious_val\n",
    "y_val = y_normal_val + y_malicious_val\n",
    "test = normal_test + malicious_test\n",
    "y_test = y_normal_test + y_malicious_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "XKT-hcKZ0O2V",
    "outputId": "92f6596d-6bd3-4c53-db57-c1a21435aab5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requests for Train data: (36639); (normal, malicious) = (15039, 21600)\n",
      "Requests for Validation data: (12213); (normal, malicious) = (5013, 7200)\n",
      "Requests for Test data: (12213); (normal, malicious) = (5013, 7200)\n",
      "Use Trigram (n=3). Split Train:Validation:Test = 6:2:2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Requests for Train data: (%d); (normal, malicious) = (%d, %d)\"%(len(train), len(normal_train), len(malicious_train)))\n",
    "print(\"Requests for Validation data: (%d); (normal, malicious) = (%d, %d)\"%(len(val), len(normal_val), len(malicious_val)))\n",
    "print(\"Requests for Test data: (%d); (normal, malicious) = (%d, %d)\"%(len(test), len(normal_test), len(malicious_test)))\n",
    "print(\"Use Trigram (n=3). Split Train:Validation:Test = 6:2:2\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W0zf7zGu0xcn"
   },
   "outputs": [],
   "source": [
    "# create dict\n",
    "char_dict = {}\n",
    "char_smpl = ' '.join(train)\n",
    "char_smpl = sorted(list(set(char_smpl)))\n",
    "for idx, ch in enumerate(char_smpl):\n",
    "    char_dict[ch] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CgZ_X3_N0TjN"
   },
   "outputs": [],
   "source": [
    "X_train = onehot_coding_data(train, char_dict)\n",
    "X_val = onehot_coding_data(val, char_dict)\n",
    "X_test = onehot_coding_data(test, char_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "tq4Geq_a1ZFJ",
    "outputId": "e10de888-42c1-464f-9bcb-9a904c0e94ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:  (36639, 300, 63)\n",
      "Shape of X_val:  (12213, 300, 63)\n",
      "Shape of X_test:  (12213, 300, 63)\n"
     ]
    }
   ],
   "source": [
    "shape = X_train.shape\n",
    "print(\"Shape of X_train: \", X_train.shape)\n",
    "print(\"Shape of X_val: \", X_val.shape)\n",
    "print(\"Shape of X_test: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8NknjhbxTIg_"
   },
   "source": [
    "## Mạng CNN cơ bản với 3 tầng Conv2D và độ rộng là 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1006
    },
    "colab_type": "code",
    "id": "afYzW_D-5yx7",
    "outputId": "d1f4ea32-6daf-4792-ad58-f68b8973c8cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 300, 63, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 298, 1, 32)        6080      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 296, 1, 32)        3104      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 294, 1, 32)        3104      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 294, 1, 32)        0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 14,465\n",
      "Trainable params: 14,465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 36639 samples, validate on 12213 samples\n",
      "Epoch 1/10\n",
      "36639/36639 [==============================] - 6s 155us/step - loss: 0.2411 - acc: 0.8761 - val_loss: 0.1518 - val_acc: 0.9257\n",
      "Epoch 2/10\n",
      "36639/36639 [==============================] - 3s 91us/step - loss: 0.0906 - acc: 0.9671 - val_loss: 0.0843 - val_acc: 0.9715\n",
      "Epoch 3/10\n",
      "36639/36639 [==============================] - 4s 98us/step - loss: 0.0723 - acc: 0.9758 - val_loss: 0.0723 - val_acc: 0.9781\n",
      "Epoch 4/10\n",
      "36639/36639 [==============================] - 4s 99us/step - loss: 0.0628 - acc: 0.9804 - val_loss: 0.0729 - val_acc: 0.9790\n",
      "Epoch 5/10\n",
      "36639/36639 [==============================] - 4s 98us/step - loss: 0.0571 - acc: 0.9823 - val_loss: 0.0697 - val_acc: 0.9801\n",
      "Epoch 6/10\n",
      "36639/36639 [==============================] - 3s 93us/step - loss: 0.0534 - acc: 0.9841 - val_loss: 0.0639 - val_acc: 0.9807\n",
      "Epoch 7/10\n",
      "36639/36639 [==============================] - 3s 92us/step - loss: 0.0516 - acc: 0.9846 - val_loss: 0.0623 - val_acc: 0.9816\n",
      "Epoch 8/10\n",
      "36639/36639 [==============================] - 3s 92us/step - loss: 0.0454 - acc: 0.9870 - val_loss: 0.0601 - val_acc: 0.9830\n",
      "Epoch 9/10\n",
      "36639/36639 [==============================] - 3s 92us/step - loss: 0.0405 - acc: 0.9885 - val_loss: 0.0716 - val_acc: 0.9771\n",
      "Epoch 10/10\n",
      "36639/36639 [==============================] - 3s 94us/step - loss: 0.0370 - acc: 0.9880 - val_loss: 0.0454 - val_acc: 0.9842\n",
      "CNN Conv2d: \t(accuracy, f1) = (0.98526, 0.98473)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Reshape((shape[1], shape[2], 1), input_shape=(shape[1], shape[2])))\n",
    "\n",
    "model.add(Conv2D(32, (3, 63), activation='relu'))\n",
    "model.add(Conv2D(32, (3, 1), activation='relu'))\n",
    "model.add(Conv2D(32, (3, 1), activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GlobalMaxPooling2D())\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=10, validation_data=(X_val, y_val))\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print_result(y_pred, y_test, 'CNN Conv2d: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Zb1SzkCTRMb"
   },
   "source": [
    "## Model 2 so với model 1 có 5 lớp Conv2D\n",
    "Nhưng kết quả đạt được không hiệu quả hơn so với model 1\n",
    "### Kết luận: Số tầng Conv2D đến một mức nào đó đã là đạt hiệu quả cao nhất, tăng thêm cũng không đạt được hiệu quả nữa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 850
    },
    "colab_type": "code",
    "id": "urS4MWut6MCr",
    "outputId": "25ce6a1b-850d-4683-b9f8-7475ca44677e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_2 (Reshape)          (None, 300, 63, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 298, 1, 32)        6080      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 296, 1, 32)        3104      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 294, 1, 32)        3104      \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 292, 1, 32)        3104      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 290, 1, 32)        3104      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 290, 1, 32)        0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_2 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 20,673\n",
      "Trainable params: 20,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36639 samples, validate on 12213 samples\n",
      "Epoch 1/10\n",
      "36639/36639 [==============================] - 4s 120us/step - loss: 0.2836 - acc: 0.8486 - val_loss: 0.1609 - val_acc: 0.9218\n",
      "Epoch 2/10\n",
      "36639/36639 [==============================] - 4s 102us/step - loss: 0.0971 - acc: 0.9610 - val_loss: 0.0826 - val_acc: 0.9718\n",
      "Epoch 3/10\n",
      "36639/36639 [==============================] - 4s 102us/step - loss: 0.0726 - acc: 0.9752 - val_loss: 0.0751 - val_acc: 0.9758\n",
      "Epoch 4/10\n",
      "36639/36639 [==============================] - 4s 104us/step - loss: 0.0622 - acc: 0.9799 - val_loss: 0.0662 - val_acc: 0.9794\n",
      "Epoch 5/10\n",
      "36639/36639 [==============================] - 4s 104us/step - loss: 0.0474 - acc: 0.9842 - val_loss: 0.0466 - val_acc: 0.9860\n",
      "Epoch 6/10\n",
      "36639/36639 [==============================] - 4s 105us/step - loss: 0.0357 - acc: 0.9881 - val_loss: 0.0423 - val_acc: 0.9863\n",
      "Epoch 7/10\n",
      "36639/36639 [==============================] - 4s 109us/step - loss: 0.0304 - acc: 0.9900 - val_loss: 0.0376 - val_acc: 0.9885\n",
      "Epoch 8/10\n",
      "36639/36639 [==============================] - 4s 109us/step - loss: 0.0277 - acc: 0.9910 - val_loss: 0.0382 - val_acc: 0.9884\n",
      "Epoch 9/10\n",
      "36639/36639 [==============================] - 4s 104us/step - loss: 0.0254 - acc: 0.9921 - val_loss: 0.0376 - val_acc: 0.9886\n",
      "Epoch 10/10\n",
      "36639/36639 [==============================] - 4s 102us/step - loss: 0.0235 - acc: 0.9928 - val_loss: 0.0338 - val_acc: 0.9889\n",
      "CNN Conv2d: \t(accuracy, f1) = (0.99124, 0.99094)\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Reshape((shape[1], shape[2], 1), input_shape=(shape[1], shape[2])))\n",
    "\n",
    "model2.add(Conv2D(32, (3, 63), activation='relu'))\n",
    "model2.add(Conv2D(32, (3, 1), activation='relu'))\n",
    "model2.add(Conv2D(32, (3, 1), activation='relu'))\n",
    "model2.add(Conv2D(32, (3, 1), activation='relu'))\n",
    "model2.add(Conv2D(32, (3, 1), activation='relu'))\n",
    "\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(GlobalMaxPooling2D())\n",
    "\n",
    "model2.add(Dense(64))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2.summary()\n",
    "model2.compile(loss='binary_crossentropy',\n",
    "               optimizer='adam',\n",
    "               metrics=['acc'])\n",
    "\n",
    "model2.fit(X_train, y_train, batch_size=128, epochs=10, validation_data=(X_val, y_val))\n",
    "\n",
    "y_pred2 = model2.predict_classes(X_test)\n",
    "print_result(y_pred2, y_test, 'CNN Conv2d: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qkb2vJOZTl3y"
   },
   "source": [
    "## Model 3 không tăng số tầng Conv2D mà tăng lên độ rộng của nó\n",
    "Kết quả đạt được đã cho thấy hiệu quả được tăng lên khi tăng độ rộng các tầng\n",
    "### Kết luận: Tăng độ rộng từng tầng Conv2D có khả năng nâng cao hiệu quả của mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 782
    },
    "colab_type": "code",
    "id": "z5P2l1WF6lBZ",
    "outputId": "d62387d9-aebe-4af2-f1c2-40c441508caa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_5 (Reshape)          (None, 300, 63, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 298, 1, 128)       24320     \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 296, 1, 128)       49280     \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 294, 1, 128)       49280     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 294, 1, 128)       0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_5 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 139,521\n",
      "Trainable params: 139,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36639 samples, validate on 12213 samples\n",
      "Epoch 1/10\n",
      "36639/36639 [==============================] - 7s 189us/step - loss: 0.1809 - acc: 0.9127 - val_loss: 0.0913 - val_acc: 0.9668\n",
      "Epoch 2/10\n",
      "36639/36639 [==============================] - 6s 170us/step - loss: 0.0567 - acc: 0.9784 - val_loss: 0.0623 - val_acc: 0.9717\n",
      "Epoch 3/10\n",
      "36639/36639 [==============================] - 6s 171us/step - loss: 0.0361 - acc: 0.9867 - val_loss: 0.0371 - val_acc: 0.9871\n",
      "Epoch 4/10\n",
      "36639/36639 [==============================] - 6s 169us/step - loss: 0.0285 - acc: 0.9898 - val_loss: 0.0383 - val_acc: 0.9874\n",
      "Epoch 5/10\n",
      "36639/36639 [==============================] - 6s 169us/step - loss: 0.0218 - acc: 0.9917 - val_loss: 0.0343 - val_acc: 0.9885\n",
      "Epoch 6/10\n",
      "36639/36639 [==============================] - 6s 170us/step - loss: 0.0163 - acc: 0.9942 - val_loss: 0.0303 - val_acc: 0.9907\n",
      "Epoch 7/10\n",
      "36639/36639 [==============================] - 6s 170us/step - loss: 0.0149 - acc: 0.9941 - val_loss: 0.0309 - val_acc: 0.9916\n",
      "Epoch 8/10\n",
      "36639/36639 [==============================] - 6s 170us/step - loss: 0.0089 - acc: 0.9970 - val_loss: 0.0329 - val_acc: 0.9911\n",
      "Epoch 9/10\n",
      "36639/36639 [==============================] - 6s 169us/step - loss: 0.0103 - acc: 0.9962 - val_loss: 0.0347 - val_acc: 0.9902\n",
      "Epoch 10/10\n",
      "36639/36639 [==============================] - 6s 169us/step - loss: 0.0077 - acc: 0.9974 - val_loss: 0.0291 - val_acc: 0.9929\n",
      "CNN Conv2d: \t(accuracy, f1) = (0.99476, 0.99458)\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "\n",
    "model3.add(Reshape((shape[1], shape[2], 1), input_shape=(shape[1], shape[2])))\n",
    "\n",
    "model3.add(Conv2D(128, (3, 63), activation='relu'))\n",
    "model3.add(Conv2D(128, (3, 1), activation='relu'))\n",
    "model3.add(Conv2D(128, (3, 1), activation='relu'))\n",
    "\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(GlobalMaxPooling2D())\n",
    "\n",
    "model3.add(Dense(128))\n",
    "model3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model3.summary()\n",
    "model3.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model3.fit(X_train, y_train, batch_size=128, epochs=10, validation_data=(X_val, y_val))\n",
    "\n",
    "y_pred3 = model3.predict_classes(X_test)\n",
    "print_result(y_pred3, y_test, 'CNN Conv2d: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RqvIs212UEPY"
   },
   "source": [
    "## Model 4 kết hợp model 2 và 3, vừa tăng số tầng Conv2D vừa tăng độ rộng của nó\n",
    "Kết quả đạt được đã không được cải thiện thêm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 850
    },
    "colab_type": "code",
    "id": "hvEAOPfH35NO",
    "outputId": "111b2afe-de9e-4585-92b7-1232496a8cbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_4 (Reshape)          (None, 300, 63, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 298, 1, 128)       24320     \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 296, 1, 128)       49280     \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 294, 1, 128)       49280     \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 292, 1, 128)       49280     \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 290, 1, 128)       49280     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 290, 1, 128)       0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_4 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 238,081\n",
      "Trainable params: 238,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36639 samples, validate on 12213 samples\n",
      "Epoch 1/10\n",
      "36639/36639 [==============================] - 9s 256us/step - loss: 0.1953 - acc: 0.9037 - val_loss: 0.1068 - val_acc: 0.9541\n",
      "Epoch 2/10\n",
      "36639/36639 [==============================] - 8s 231us/step - loss: 0.0747 - acc: 0.9745 - val_loss: 0.0677 - val_acc: 0.9792\n",
      "Epoch 3/10\n",
      "36639/36639 [==============================] - 8s 231us/step - loss: 0.0630 - acc: 0.9800 - val_loss: 0.0785 - val_acc: 0.9756\n",
      "Epoch 4/10\n",
      "36639/36639 [==============================] - 9s 236us/step - loss: 0.0561 - acc: 0.9829 - val_loss: 0.0908 - val_acc: 0.9711\n",
      "Epoch 5/10\n",
      "36639/36639 [==============================] - 9s 233us/step - loss: 0.0527 - acc: 0.9846 - val_loss: 0.0611 - val_acc: 0.9831\n",
      "Epoch 6/10\n",
      "36639/36639 [==============================] - 8s 229us/step - loss: 0.0489 - acc: 0.9859 - val_loss: 0.0582 - val_acc: 0.9834\n",
      "Epoch 7/10\n",
      "36639/36639 [==============================] - 8s 229us/step - loss: 0.0437 - acc: 0.9878 - val_loss: 0.0586 - val_acc: 0.9845\n",
      "Epoch 8/10\n",
      "36639/36639 [==============================] - 9s 232us/step - loss: 0.0411 - acc: 0.9889 - val_loss: 0.0611 - val_acc: 0.9819\n",
      "Epoch 9/10\n",
      "36639/36639 [==============================] - 8s 229us/step - loss: 0.0327 - acc: 0.9905 - val_loss: 0.0387 - val_acc: 0.9898\n",
      "Epoch 10/10\n",
      "36639/36639 [==============================] - 8s 230us/step - loss: 0.0179 - acc: 0.9942 - val_loss: 0.0371 - val_acc: 0.9904\n",
      "CNN Conv2d: \t(accuracy, f1) = (0.99173, 0.99145)\n"
     ]
    }
   ],
   "source": [
    "model4 = Sequential()\n",
    "\n",
    "model4.add(Reshape((shape[1], shape[2], 1), input_shape=(shape[1], shape[2])))\n",
    "\n",
    "model4.add(Conv2D(128, (3, 63), activation='relu'))\n",
    "model4.add(Conv2D(128, (3, 1), activation='relu'))\n",
    "model4.add(Conv2D(128, (3, 1), activation='relu'))\n",
    "model4.add(Conv2D(128, (3, 1), activation='relu'))\n",
    "model4.add(Conv2D(128, (3, 1), activation='relu'))\n",
    "\n",
    "model4.add(Dropout(0.2))\n",
    "model4.add(GlobalMaxPooling2D())\n",
    "\n",
    "model4.add(Dense(128))\n",
    "model4.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model4.summary()\n",
    "model4.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model4.fit(X_train, y_train, batch_size=128, epochs=10, validation_data=(X_val, y_val))\n",
    "\n",
    "y_pred4 = model4.predict_classes(X_test)\n",
    "print_result(y_pred4, y_test, 'CNN Conv2d: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m9t9zK-SLexB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DL-CNN-CSIC.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
