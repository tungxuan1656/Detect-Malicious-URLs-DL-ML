{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL-CNN-CSIC.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRRNvycP1ZE3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "00958712-ce5f-4c1d-971e-f65694e9f2cb"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from keras.layers import Dense, Activation, Dropout, Conv2D, MaxPooling2D, GlobalMaxPooling2D, Reshape\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHzwSb3K1ZE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadData(file):\n",
        "    with open(file, 'r', encoding=\"utf8\") as f:\n",
        "        data = f.readlines()\n",
        "    result = []\n",
        "    for d in data:\n",
        "        d = d.strip()\n",
        "        if (len(d) > 0):\n",
        "            result.append(d)\n",
        "    return result\n",
        "def print_result(y_pred, y_test, clf_name):\n",
        "    ACC = accuracy_score(y_pred, y_test)\n",
        "    F1 = f1_score(y_pred, y_test, average='macro')\n",
        "    print(\"%s\\t(accuracy, f1) = (%.5f, %.5f)\"%(clf_name, ACC, F1))\n",
        "def process_raw_data(normal_data, anomalous_data):\n",
        "    # create dict\n",
        "    char_dict = {}\n",
        "    char_smpl = ' '.join(anomalous_data)\n",
        "    char_smpl = sorted(list(set(char_smpl)))\n",
        "    for idx, ch in enumerate(char_smpl):\n",
        "        char_dict[ch] = idx\n",
        "    # convert\n",
        "    normal_data = [[char_dict[el] for el in line] for line in normal_data]\n",
        "    anomalous_data = [[char_dict[el] for el in line] for line in anomalous_data]\n",
        "    # merge data and create target data\n",
        "    data = normal_data + anomalous_data\n",
        "    # train_target = np.ones(len(normal_data)).tolist() + np.zeros(len(anomalous_data)).tolist()\n",
        "    target = [1]*len(normal_data) + [0]*len(anomalous_data)\n",
        "    print('Good requests:', len(normal_data))\n",
        "    print('Bad requests:', len(anomalous_data))\n",
        "    print('Total requests:', len(target))\n",
        "    # set max len element of data\n",
        "    for i in range(len(data)):\n",
        "        if (len(data[i]) < 300):\n",
        "            data[i] = data[i] + [0]*(300 - len(data[i]))\n",
        "        else:\n",
        "            data[i] = data[i][:300]\n",
        "    # split\n",
        "    train_data, test_data, y_train, y_test = train_test_split(data, target, test_size = 0.2, random_state = 22)\n",
        "    train_data, val_data, y_train, y_val = train_test_split(train_data, y_train, test_size=0.25, random_state = 11)\n",
        "    # one-hot vector\n",
        "    X_train = np.asarray([to_categorical(i, num_classes=63) for i in train_data])\n",
        "    X_val = np.asarray([to_categorical(i, num_classes=63) for i in val_data])\n",
        "    X_test = np.asarray([to_categorical(i, num_classes=63) for i in test_data])\n",
        "    # print\n",
        "    print(\"Requests for Train: \", len(y_train))\n",
        "    print(\"Requests for Validation: \", len(y_val))\n",
        "    print(\"Requests for Test: \", len(y_test))\n",
        "    print(\"Split Train:Validation:Test = 6:2:2\")\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJCBfNV91ZFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normal_data = loadData('normalRequest.txt')\n",
        "anomalous_data = loadData('anomalousRequest.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHtrAQ7Z1ZFE",
        "colab_type": "code",
        "outputId": "da5d8eb9-a77f-4143-87f9-0d61a081f3b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "X_train, X_val, X_test, y_train, y_val, y_test = process_raw_data(normal_data, anomalous_data)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Good requests: 36000\n",
            "Bad requests: 25065\n",
            "Total requests: 61065\n",
            "Requests for Train:  36639\n",
            "Requests for Validation:  12213\n",
            "Requests for Test:  12213\n",
            "Split Train:Validation:Test = 6:2:2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tq4Geq_a1ZFJ",
        "colab_type": "code",
        "outputId": "98cb0641-892d-44b3-a510-e908d15fcf56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "shape = X_train.shape\n",
        "print(shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(36639, 300, 63)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NknjhbxTIg_",
        "colab_type": "text"
      },
      "source": [
        "## Mạng CNN cơ bản với 3 tầng Conv2D và độ rộng là 32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afYzW_D-5yx7",
        "colab_type": "code",
        "outputId": "a4b3d485-ad18-4ce7-a4b1-0ba58a113988",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1006
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Reshape((shape[1], shape[2], 1), input_shape=(shape[1], shape[2])))\n",
        "\n",
        "model.add(Conv2D(32, (3, 63), activation='relu'))\n",
        "model.add(Conv2D(32, (3, 1), activation='relu'))\n",
        "model.add(Conv2D(32, (3, 1), activation='relu'))\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "model.add(GlobalMaxPooling2D())\n",
        "\n",
        "model.add(Dense(64))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])\n",
        "\n",
        "model.fit(X_train, y_train, batch_size=128, epochs=10, validation_data=(X_val, y_val))\n",
        "\n",
        "y_pred = model.predict_classes(X_test)\n",
        "print_result(y_pred, y_test, 'CNN Conv2d: ')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_1 (Reshape)          (None, 300, 63, 1)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 298, 1, 32)        6080      \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 296, 1, 32)        3104      \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 294, 1, 32)        3104      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 294, 1, 32)        0         \n",
            "_________________________________________________________________\n",
            "global_max_pooling2d_1 (Glob (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 14,465\n",
            "Trainable params: 14,465\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Train on 36639 samples, validate on 12213 samples\n",
            "Epoch 1/10\n",
            "36639/36639 [==============================] - 6s 158us/step - loss: 0.2457 - acc: 0.8756 - val_loss: 0.0988 - val_acc: 0.9636\n",
            "Epoch 2/10\n",
            "36639/36639 [==============================] - 3s 88us/step - loss: 0.0835 - acc: 0.9700 - val_loss: 0.0634 - val_acc: 0.9791\n",
            "Epoch 3/10\n",
            "36639/36639 [==============================] - 3s 89us/step - loss: 0.0518 - acc: 0.9811 - val_loss: 0.0550 - val_acc: 0.9795\n",
            "Epoch 4/10\n",
            "36639/36639 [==============================] - 3s 90us/step - loss: 0.0406 - acc: 0.9854 - val_loss: 0.0437 - val_acc: 0.9844\n",
            "Epoch 5/10\n",
            "36639/36639 [==============================] - 3s 88us/step - loss: 0.0311 - acc: 0.9887 - val_loss: 0.0364 - val_acc: 0.9867\n",
            "Epoch 6/10\n",
            "36639/36639 [==============================] - 3s 89us/step - loss: 0.0252 - acc: 0.9910 - val_loss: 0.0325 - val_acc: 0.9888\n",
            "Epoch 7/10\n",
            "36639/36639 [==============================] - 3s 91us/step - loss: 0.0211 - acc: 0.9927 - val_loss: 0.0362 - val_acc: 0.9884\n",
            "Epoch 8/10\n",
            "36639/36639 [==============================] - 3s 89us/step - loss: 0.0197 - acc: 0.9929 - val_loss: 0.0338 - val_acc: 0.9888\n",
            "Epoch 9/10\n",
            "36639/36639 [==============================] - 3s 90us/step - loss: 0.0164 - acc: 0.9941 - val_loss: 0.0318 - val_acc: 0.9896\n",
            "Epoch 10/10\n",
            "36639/36639 [==============================] - 3s 92us/step - loss: 0.0141 - acc: 0.9949 - val_loss: 0.0268 - val_acc: 0.9922\n",
            "CNN Conv2d: \t(accuracy, f1) = (0.99124, 0.99094)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Zb1SzkCTRMb",
        "colab_type": "text"
      },
      "source": [
        "## Model 2 so với model 1 có 5 lớp Conv2D\n",
        "Nhưng kết quả đạt được không hiệu quả hơn so với model 1\n",
        "### Kết luận: Số tầng Conv2D đến một mức nào đó đã là đạt hiệu quả cao nhất, tăng thêm cũng không đạt được hiệu quả nữa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urS4MWut6MCr",
        "colab_type": "code",
        "outputId": "747ca793-886c-4a54-fcdf-252cd468df56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        }
      },
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Reshape((shape[1], shape[2], 1), input_shape=(shape[1], shape[2])))\n",
        "\n",
        "model2.add(Conv2D(32, (3, 63), activation='relu'))\n",
        "model2.add(Conv2D(32, (3, 1), activation='relu'))\n",
        "model2.add(Conv2D(32, (3, 1), activation='relu'))\n",
        "model2.add(Conv2D(32, (3, 1), activation='relu'))\n",
        "model2.add(Conv2D(32, (3, 1), activation='relu'))\n",
        "\n",
        "model2.add(Dropout(0.25))\n",
        "model2.add(GlobalMaxPooling2D())\n",
        "\n",
        "model2.add(Dense(64))\n",
        "model2.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model2.summary()\n",
        "model2.compile(loss='binary_crossentropy',\n",
        "               optimizer='adam',\n",
        "               metrics=['acc'])\n",
        "\n",
        "model2.fit(X_train, y_train, batch_size=128, epochs=10, validation_data=(X_val, y_val))\n",
        "\n",
        "y_pred2 = model2.predict_classes(X_test)\n",
        "print_result(y_pred2, y_test, 'CNN Conv2d: ')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_2 (Reshape)          (None, 300, 63, 1)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 298, 1, 32)        6080      \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 296, 1, 32)        3104      \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 294, 1, 32)        3104      \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 292, 1, 32)        3104      \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 290, 1, 32)        3104      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 290, 1, 32)        0         \n",
            "_________________________________________________________________\n",
            "global_max_pooling2d_2 (Glob (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 20,673\n",
            "Trainable params: 20,673\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 36639 samples, validate on 12213 samples\n",
            "Epoch 1/10\n",
            "36639/36639 [==============================] - 4s 116us/step - loss: 0.2203 - acc: 0.8915 - val_loss: 0.1005 - val_acc: 0.9642\n",
            "Epoch 2/10\n",
            "36639/36639 [==============================] - 4s 103us/step - loss: 0.0908 - acc: 0.9675 - val_loss: 0.0864 - val_acc: 0.9684\n",
            "Epoch 3/10\n",
            "36639/36639 [==============================] - 4s 104us/step - loss: 0.0783 - acc: 0.9722 - val_loss: 0.1033 - val_acc: 0.9596\n",
            "Epoch 4/10\n",
            "36639/36639 [==============================] - 4s 106us/step - loss: 0.0693 - acc: 0.9769 - val_loss: 0.0790 - val_acc: 0.9726\n",
            "Epoch 5/10\n",
            "36639/36639 [==============================] - 4s 101us/step - loss: 0.0629 - acc: 0.9800 - val_loss: 0.0752 - val_acc: 0.9770\n",
            "Epoch 6/10\n",
            "36639/36639 [==============================] - 4s 100us/step - loss: 0.0563 - acc: 0.9828 - val_loss: 0.0677 - val_acc: 0.9787\n",
            "Epoch 7/10\n",
            "36639/36639 [==============================] - 4s 107us/step - loss: 0.0502 - acc: 0.9853 - val_loss: 0.0656 - val_acc: 0.9793\n",
            "Epoch 8/10\n",
            "36639/36639 [==============================] - 4s 100us/step - loss: 0.0483 - acc: 0.9862 - val_loss: 0.0862 - val_acc: 0.9741\n",
            "Epoch 9/10\n",
            "36639/36639 [==============================] - 4s 99us/step - loss: 0.0460 - acc: 0.9871 - val_loss: 0.0618 - val_acc: 0.9825\n",
            "Epoch 10/10\n",
            "36639/36639 [==============================] - 4s 100us/step - loss: 0.0413 - acc: 0.9891 - val_loss: 0.0615 - val_acc: 0.9835\n",
            "CNN Conv2d: \t(accuracy, f1) = (0.98240, 0.98174)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qkb2vJOZTl3y",
        "colab_type": "text"
      },
      "source": [
        "## Model 3 không tăng số tầng Conv2D mà tăng lên độ rộng của nó\n",
        "Kết quả đạt được đã cho thấy hiệu quả được tăng lên khi tăng độ rộng các tầng\n",
        "### Kết luận: Tăng độ rộng từng tầng Conv2D có khả năng nâng cao hiệu quả của mô hình"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5P2l1WF6lBZ",
        "colab_type": "code",
        "outputId": "520be8ef-6691-444d-be2b-0a281b0247cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        }
      },
      "source": [
        "model3 = Sequential()\n",
        "\n",
        "model3.add(Reshape((shape[1], shape[2], 1), input_shape=(shape[1], shape[2])))\n",
        "\n",
        "model3.add(Conv2D(128, (3, 63), activation='relu'))\n",
        "model3.add(Conv2D(128, (3, 1), activation='relu'))\n",
        "model3.add(Conv2D(128, (3, 1), activation='relu'))\n",
        "\n",
        "model3.add(Dropout(0.25))\n",
        "model3.add(GlobalMaxPooling2D())\n",
        "\n",
        "model3.add(Dense(128))\n",
        "model3.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model3.summary()\n",
        "model3.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])\n",
        "\n",
        "model3.fit(X_train, y_train, batch_size=128, epochs=10, validation_data=(X_val, y_val))\n",
        "\n",
        "y_pred3 = model3.predict_classes(X_test)\n",
        "print_result(y_pred3, y_test, 'CNN Conv2d: ')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_3 (Reshape)          (None, 300, 63, 1)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 298, 1, 128)       24320     \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 296, 1, 128)       49280     \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 294, 1, 128)       49280     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 294, 1, 128)       0         \n",
            "_________________________________________________________________\n",
            "global_max_pooling2d_3 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 139,521\n",
            "Trainable params: 139,521\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 36639 samples, validate on 12213 samples\n",
            "Epoch 1/10\n",
            "36639/36639 [==============================] - 7s 187us/step - loss: 0.1914 - acc: 0.9070 - val_loss: 0.0772 - val_acc: 0.9710\n",
            "Epoch 2/10\n",
            "36639/36639 [==============================] - 6s 166us/step - loss: 0.0514 - acc: 0.9803 - val_loss: 0.0454 - val_acc: 0.9837\n",
            "Epoch 3/10\n",
            "36639/36639 [==============================] - 6s 166us/step - loss: 0.0335 - acc: 0.9881 - val_loss: 0.0364 - val_acc: 0.9859\n",
            "Epoch 4/10\n",
            "36639/36639 [==============================] - 6s 166us/step - loss: 0.0276 - acc: 0.9900 - val_loss: 0.0329 - val_acc: 0.9889\n",
            "Epoch 5/10\n",
            "36639/36639 [==============================] - 6s 166us/step - loss: 0.0235 - acc: 0.9916 - val_loss: 0.0291 - val_acc: 0.9898\n",
            "Epoch 6/10\n",
            "36639/36639 [==============================] - 6s 165us/step - loss: 0.0182 - acc: 0.9930 - val_loss: 0.0288 - val_acc: 0.9898\n",
            "Epoch 7/10\n",
            "36639/36639 [==============================] - 6s 165us/step - loss: 0.0149 - acc: 0.9952 - val_loss: 0.0268 - val_acc: 0.9914\n",
            "Epoch 8/10\n",
            "36639/36639 [==============================] - 6s 166us/step - loss: 0.0122 - acc: 0.9959 - val_loss: 0.0321 - val_acc: 0.9909\n",
            "Epoch 9/10\n",
            "36639/36639 [==============================] - 6s 168us/step - loss: 0.0120 - acc: 0.9959 - val_loss: 0.0306 - val_acc: 0.9912\n",
            "Epoch 10/10\n",
            "36639/36639 [==============================] - 6s 165us/step - loss: 0.0084 - acc: 0.9972 - val_loss: 0.0333 - val_acc: 0.9905\n",
            "CNN Conv2d: \t(accuracy, f1) = (0.99247, 0.99221)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqvIs212UEPY",
        "colab_type": "text"
      },
      "source": [
        "## Model 4 kết hợp model 2 và 3, vừa tăng số tầng Conv2D vừa tăng độ rộng của nó\n",
        "Kết quả đạt được đã không được cải thiện thêm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvEAOPfH35NO",
        "colab_type": "code",
        "outputId": "d348aa21-688e-4b34-e653-641216dc3e86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        }
      },
      "source": [
        "model4 = Sequential()\n",
        "\n",
        "model4.add(Reshape((shape[1], shape[2], 1), input_shape=(shape[1], shape[2])))\n",
        "\n",
        "model4.add(Conv2D(128, (3, 63), activation='relu'))\n",
        "model4.add(Conv2D(128, (3, 1), activation='relu'))\n",
        "model4.add(Conv2D(128, (3, 1), activation='relu'))\n",
        "model4.add(Conv2D(128, (3, 1), activation='relu'))\n",
        "model4.add(Conv2D(128, (3, 1), activation='relu'))\n",
        "\n",
        "model4.add(Dropout(0.25))\n",
        "model4.add(GlobalMaxPooling2D())\n",
        "\n",
        "model4.add(Dense(128))\n",
        "model4.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model4.summary()\n",
        "model4.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])\n",
        "\n",
        "model4.fit(X_train, y_train, batch_size=128, epochs=10, validation_data=(X_val, y_val))\n",
        "\n",
        "y_pred4 = model4.predict_classes(X_test)\n",
        "print_result(y_pred4, y_test, 'CNN Conv2d: ')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_4 (Reshape)          (None, 300, 63, 1)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 298, 1, 128)       24320     \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 296, 1, 128)       49280     \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 294, 1, 128)       49280     \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 292, 1, 128)       49280     \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 290, 1, 128)       49280     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 290, 1, 128)       0         \n",
            "_________________________________________________________________\n",
            "global_max_pooling2d_4 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 238,081\n",
            "Trainable params: 238,081\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 36639 samples, validate on 12213 samples\n",
            "Epoch 1/10\n",
            "36639/36639 [==============================] - 9s 249us/step - loss: 0.2105 - acc: 0.8951 - val_loss: 0.1154 - val_acc: 0.9590\n",
            "Epoch 2/10\n",
            "36639/36639 [==============================] - 8s 227us/step - loss: 0.0804 - acc: 0.9726 - val_loss: 0.0775 - val_acc: 0.9737\n",
            "Epoch 3/10\n",
            "36639/36639 [==============================] - 8s 225us/step - loss: 0.0679 - acc: 0.9780 - val_loss: 0.0707 - val_acc: 0.9774\n",
            "Epoch 4/10\n",
            "36639/36639 [==============================] - 8s 226us/step - loss: 0.0598 - acc: 0.9817 - val_loss: 0.0705 - val_acc: 0.9788\n",
            "Epoch 5/10\n",
            "36639/36639 [==============================] - 8s 226us/step - loss: 0.0538 - acc: 0.9842 - val_loss: 0.0649 - val_acc: 0.9804\n",
            "Epoch 6/10\n",
            "36639/36639 [==============================] - 8s 226us/step - loss: 0.0510 - acc: 0.9853 - val_loss: 0.0699 - val_acc: 0.9794\n",
            "Epoch 7/10\n",
            "36639/36639 [==============================] - 8s 225us/step - loss: 0.0358 - acc: 0.9888 - val_loss: 0.0431 - val_acc: 0.9873\n",
            "Epoch 8/10\n",
            "36639/36639 [==============================] - 8s 228us/step - loss: 0.0262 - acc: 0.9915 - val_loss: 0.0387 - val_acc: 0.9886\n",
            "Epoch 9/10\n",
            "36639/36639 [==============================] - 8s 228us/step - loss: 0.0230 - acc: 0.9928 - val_loss: 0.0545 - val_acc: 0.9863\n",
            "Epoch 10/10\n",
            "36639/36639 [==============================] - 8s 225us/step - loss: 0.0202 - acc: 0.9937 - val_loss: 0.0472 - val_acc: 0.9853\n",
            "CNN Conv2d: \t(accuracy, f1) = (0.98649, 0.98596)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9t9zK-SLexB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}